I am going to give you a fairly long set of instructions for creating a script I need. Review the instructions, and if you have any questions about my intent, then ask me to clarify. If you believe that everything is clear, then tell me that everything is clear. After you respond, then I will either give you revised instructions or tell you to proceed to create the script using the latest instructions. The script I need is in Python 3.13.

All files referenced will be in the same directory as the python script. All CSV files are comma-delimited with a header row and UTF-8 encoding. Read them with encoding="utf-8-sig". When you create folders and file names, no sanitization is necessary as they all already contain either letters, numbers or space.

I have a file named "pmj.csv". It has about 200 rows and these columns:
Site ID	Site Name	Male Song	Male Chorus	Female Song	HTCH	NEST	FLDG	Insect sp30	Insect sp31	Insect sp32	Insect sp33	Pacific Tree Frog	Red-legged Frog	Bull Frog

There is another file named "pattern_matchings.0001.csv". It has about 3000 rows and these columns:
pattern_matching_id	name	timestamp	playlist_id	playlist_name	template_id	template_name	parameters

There are three files named pattern_matching_rois.0001.csv, pattern_matching_rois.0002.csv, and pattern_matching_rois.0003.csv. Across the three files, there is about 28MB of data in total. There are these columns:
pattern_matching_id	recording_id	species_id	songtype_id	x1	x2	y1	y2	score	validated

There are 79 files named "recordings.00nn.csv" where nn is a number from 00 to 79. For example, the first file is named recordings.0000.csv and the last is recordings.0079.csv. Across all the files, there is about 900MB of data in total. These files have the following columns:
recording_id	site_id	datetime	datetime_utc	sample_rate	duration	samples	file_size	bit_rate	sample_encoding	upload_time	meta	url

The first time you load all the recordings in the flow below, load all 79 recordings.*.csv files into a single big dataframe or dictionary keyed by site_id and recording_id. Keep only the three columns we care about: recording_id, site_id, datetime. Also cache the index (maybe pickle it as recordings_index.pkl) so you donâ€™t have to rebuild it every run.

All numeric-looking values below (e.g. "Site ID" or pattern_matching_id) look like numbers but should be treated like strings. If they start with a 0 then keep this value.

I need to map column names in pmj.csv to strings for output, as in {Column Name:Output File String}. The map is:
{"Male Song":"Male Song",
 "Male Chorus":"Male Chorus", 
 "Female Song":"Female",
 "HTCH":"Hatchling", 
 "NEST":"Nestling",
 "FLDG":"Fledgling", 
 "Insect sp30":"Insect 30",
 "Insect sp31":"Insect 31",
 "Insect sp32":"Insect 32",
 "Insect sp33":"Insect 33",
 "Pacific Tree Frog":"Pacific Tree Frog",
 "Red-legged Frog":"Red-legged Frog",
 "Bull Frog":"Bull Frog"}

Any messages to the user should be logged to a file called "results.txt" and printed. Below, where I write things like "log a message", I want the text of the message printed and saved to the results.txt file. You can log any other messages you think would be helpful for debugging in addition to what I call out below. If results.txt already exists, rename it to "results backup {date_time}.txt" where date_time is the current date and time. The format should be YYYY-MM-DD_hh-mm, such as "results backup 2025-09-07_14-55.txt". If there already is a file of that name, add "(2)" to the end. Then create a new one. Include timestamps in log lines.

So, the work to be done is:

1. Create a folder called "PMJ Data" in the current working directory. If this already exists, rename the current one as "PMJ Data backup {date_time}" where date_time is the current date and time. The format should be YYYY-MM-DD_hh-mm, such as "PMJ Data backup 2025-09-07_14-55". If there already is a file of that name, add "(2)" to the end.
2. Load the file pmj.csv.
3. For each row in pmj.csv
	1. Get the "Site ID", which in this example is 2059, and the "Site Name", which is "2017 Rush Ranch". 
Site ID	Site Name	Male Song	Male Chorus	Female Song	HTCH	NEST	FLDG	Insect sp30	Insect sp31	Insect sp32	Insect sp33	Pacific Tree Frog	Red-legged Frog	Bull Frog
2059	2017 Rush Ranch	2017 RR MStyp5	2017 RR MC01	2017 RR FS01	2017 RR Hatchling	2017 RR Nestling	2017 RR FC06						

	2. Make a new folder inside "PMJ Data", with the new folder named the Site Name from step 1. This should not exist, but if it does, log an error and go to the next row.

	3. Search across all the recordings*.csv files and get every row where "site_id" matches the "Site ID" from the step above. We need to keep only the following columns for each row: "recording_id", "site_id", "datetime". Call this recordings_df. This could be up to 10,000 rows. We will use this later.

	4. For each column name (key) in the map dictionary:
		1. Get the corresponding value in pmj.csv for that site and column. For the following row, for "Site Name"="Rush Ranch 2017" and "Male Song", the value is "2017 RR MStyp5". This is the pattern_matching_name. Example rows:
Site ID	Site Name	Male Song	Male Chorus	Female Song	HTCH	NEST	FLDG	Insect sp30	Insect sp31	Insect sp32	Insect sp33	Pacific Tree Frog	Red-legged Frog	Bull Frog
2059	2017 Rush Ranch	2017 RR MStyp5	2017 RR MC01	2017 RR FS01	2017 RR Hatchling	2017 RR Nestling	2017 RR FC06						
		If the value of the pattern_matching_name is empty or "ND" (case insensive and trim surrounding whitespace) then log this as "note: {site_name} and {key} skipped due to ND or empty". Go to the next key. You only need to look for "ND", not other values like "n/a". An empty "{Site Name} {Output File Name}.csv" generated below must not be written in this case.

		2. Look up the pattern_matching_name in the "name" column of pattern_matchings.0001.csv and get the value of "pattern_matching_id" from that row. In the example below, the value of pattern_matching_id for "2017 RR MStyp5" is 75124.
pattern_matching_id	name	timestamp	playlist_id	playlist_name	template_id	template_name	parameters
75124	2017 RR MStyp5	9/6/2024 23:30	16405	2017 Rush Ranch	16970	Male Song Type 5	{"threshold": 0.2, "N": 1}
		If no pattern_matching_id is found, log an error in the format "error: No pattern matching id found for {pattern_matching_name}, id {pattern_matching_id}" and go to the next key.
		If more than one pattern_matching_id is found, log an error containing both the pattern_matching_name and the pattern_matching_id, and just use the first one in occurrence of file order of the pattern_matchings* file.
		
		3. Find all rows in the files "pattern_matchings_rois*.csv" that have this pattern_matching_id in the column "pattern_matching_id". In the example below, there are three rows that match:
pattern_matching_id	recording_id	species_id	songtype_id	x1	x2	y1	y2	score	validated
75124	57628048	9897	1	55.93106461	58.14276505	861	3359	0.230401769	1
75124	57628105	9897	1	34.69061279	36.90231323	861	3359	0.420945346	1
75124	57628120	9897	1	23.57405853	25.78575897	861	3359	0.208992526	1
		If no rows are returned, log a message in the format "note: no recordings found for pattern matching job {pattern_matching_name}, id {pattern_matching_id}".

		4. Make a new table that has the following columns: "site_id", "site", "recording_id", "year", "month", "day", "validated". call this table "pattern_matching_results".

		5. For each row from step 3.4.3, (if there were no rows, then skip this)
			1. Get the recording_id, look it up in recordings_df, and get the value of "datetime" for that recording. This will look like "4/24/2017 7:40 AM". This will represent a time from the Pacific time zone and will be in a consistent format. From this, extract the year, month, and day. For this example, year=2017, month=4, and day=24". If the recording_id isn't present, log an error and skip that row. 
			2. Write the following information to a new row in pattern_matching_results: "site_id"=the site ID from step 3.1; "site"="Site Name" from step 3.1; "recording_id"=recording_id for the current row from step 4; "year"=year from the prior step; "month"=month from the prior step; "day"=day from the prior step; "validated"= one of three values: "present" if the value for "validated" for the current row from step 4 is "1", "not present" if the value is "0", or if blank or has another value "(not validated)". If this row already contains a recording_id with the same value, then log an error and do NOT add the duplicate row.
		
		6. Sort pattern_matching_results by date (year, month, day), then recording_id (if there were no rows, then skip this)

		7. Create a new file inside the folder PMJ Data/{Site Name} named "{Site Name} {Output File Name}.csv", where Site Name is the site name from step 3.1, and Output File Name is the value in the columns name map for the current key. For example, if the key is "HTCH" and the "Site Name" is "2017 Rush Ranch", then the new file should be named "2017 Rush Ranch Hatchling.csv".  Write the pattern_matching_results table to this file and then close the file. Do not add utf-8-sig encoding here. If there were no rows found in step 3.4.3 then the file should just have headers but otherwise be empty.

